{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":98084,"databundleVersionId":11711500,"sourceType":"competition"}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Starter Notebook","metadata":{"id":"a02285e6"}},{"cell_type":"markdown","source":"Install and import required libraries","metadata":{"id":"bdcc5329"}},{"cell_type":"markdown","source":"V1 Accuracy 94.19% 84.425% on unlabelled","metadata":{}},{"cell_type":"code","source":"# !pip install transformers datasets evaluate accelerate peft trl bitsandbytes\n!pip install nvidia-ml-py3","metadata":{"id":"348ceed6-b684-46c3-8a32-9bb640c9a9d7","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T02:20:42.659290Z","iopub.execute_input":"2025-04-13T02:20:42.659524Z","iopub.status.idle":"2025-04-13T02:20:49.400014Z","shell.execute_reply.started":"2025-04-13T02:20:42.659500Z","shell.execute_reply":"2025-04-13T02:20:49.399072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom transformers import RobertaModel, RobertaTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding, RobertaForSequenceClassification\nfrom peft import LoraConfig, get_peft_model, PeftModel\nfrom datasets import load_dataset, Dataset, ClassLabel\nimport pickle","metadata":{"id":"cca64f38-d8d2-4313-8295-fbbd43c2a263","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T02:20:49.401931Z","iopub.execute_input":"2025-04-13T02:20:49.402215Z","iopub.status.idle":"2025-04-13T02:21:19.238758Z","shell.execute_reply.started":"2025-04-13T02:20:49.402185Z","shell.execute_reply":"2025-04-13T02:21:19.238165Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load Tokenizer and Preprocess Data","metadata":{"id":"59d6e377"}},{"cell_type":"code","source":"base_model = 'roberta-base'\n\ndataset = load_dataset('ag_news', split='train')\ntokenizer = RobertaTokenizer.from_pretrained(base_model)\n\ndef preprocess(examples):\n    tokenized = tokenizer(examples['text'], truncation=True, padding=True)\n    return tokenized\n\ntokenized_dataset = dataset.map(preprocess, batched=True,  remove_columns=[\"text\"])\ntokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")","metadata":{"id":"21f42747-f551-40a5-a95f-7affb1eba4a3","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T02:21:19.239598Z","iopub.execute_input":"2025-04-13T02:21:19.240144Z","iopub.status.idle":"2025-04-13T02:22:26.071024Z","shell.execute_reply.started":"2025-04-13T02:21:19.240122Z","shell.execute_reply":"2025-04-13T02:22:26.070502Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Extract the number of classess and their names\nnum_labels = dataset.features['label'].num_classes\nclass_names = dataset.features[\"label\"].names\nprint(f\"number of labels: {num_labels}\")\nprint(f\"the labels: {class_names}\")\n\n# Create an id2label mapping\n# We will need this for our classifier.\nid2label = {i: label for i, label in enumerate(class_names)}\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n","metadata":{"id":"9e07f641-bec0-43a6-8c26-510d7642916a","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T02:22:26.071807Z","iopub.execute_input":"2025-04-13T02:22:26.072114Z","iopub.status.idle":"2025-04-13T02:22:26.077539Z","shell.execute_reply.started":"2025-04-13T02:22:26.072079Z","shell.execute_reply":"2025-04-13T02:22:26.076742Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Load Pre-trained Model\nSet up config for pretrained model and download it from hugging face","metadata":{"id":"c9e24afd"}},{"cell_type":"code","source":"model = RobertaForSequenceClassification.from_pretrained(\n    base_model,\n    id2label=id2label)\nmodel","metadata":{"id":"262a8416-a59c-4ea1-95d9-0b1f81d6094c","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T02:22:26.079518Z","iopub.execute_input":"2025-04-13T02:22:26.079728Z","iopub.status.idle":"2025-04-13T02:22:29.655754Z","shell.execute_reply.started":"2025-04-13T02:22:26.079713Z","shell.execute_reply":"2025-04-13T02:22:29.655116Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Anything from here on can be modified","metadata":{"id":"f265839d-a088-4693-8474-862641de11ed"}},{"cell_type":"code","source":"# Split the original training set\nsplit_datasets = tokenized_dataset.train_test_split(test_size=20000, seed=42)\ntrain_dataset = split_datasets['train']\neval_dataset = split_datasets['test']\n\nprint(train_dataset.shape)\nprint(eval_dataset.shape)","metadata":{"id":"e7413430-be57-482b-856e-36bd4ba799df","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T02:22:29.656562Z","iopub.execute_input":"2025-04-13T02:22:29.656795Z","iopub.status.idle":"2025-04-13T02:22:29.696397Z","shell.execute_reply.started":"2025-04-13T02:22:29.656777Z","shell.execute_reply":"2025-04-13T02:22:29.695593Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Setup LoRA Config\nSetup PEFT config and get peft model for finetuning","metadata":{"id":"652452e3"}},{"cell_type":"code","source":"!pip install peft accelerate transformers datasets\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T02:22:29.697289Z","iopub.execute_input":"2025-04-13T02:22:29.697909Z","iopub.status.idle":"2025-04-13T02:23:51.122679Z","shell.execute_reply.started":"2025-04-13T02:22:29.697889Z","shell.execute_reply":"2025-04-13T02:23:51.121614Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from peft import get_peft_model, LoraConfig, TaskType\n\n# Configure LoRA\nlora_config = LoraConfig(\n    r=8,  # rank\n    lora_alpha=16,\n    target_modules=[\"query\", \"value\"],  # works for transformers like RoBERTa\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=TaskType.SEQ_CLS  # sequence classification\n)\n\n# Wrap the model with PEFT\nmodel = get_peft_model(model, lora_config)\nmodel","metadata":{"id":"bd0ca0ea-86b8-47f7-8cbf-83da25685876","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T02:23:51.124016Z","iopub.execute_input":"2025-04-13T02:23:51.124376Z","iopub.status.idle":"2025-04-13T02:23:51.190046Z","shell.execute_reply.started":"2025-04-13T02:23:51.124343Z","shell.execute_reply":"2025-04-13T02:23:51.189184Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"peft_model = get_peft_model(model, lora_config)\npeft_model","metadata":{"id":"6ec2739d-76b6-4fde-91c2-0fc49e1884b0","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T02:23:51.191047Z","iopub.execute_input":"2025-04-13T02:23:51.191350Z","iopub.status.idle":"2025-04-13T02:23:51.229495Z","shell.execute_reply.started":"2025-04-13T02:23:51.191331Z","shell.execute_reply":"2025-04-13T02:23:51.228823Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Trainable parameters:\")\ncount = 0\nfor name, param in peft_model.named_parameters():\n    if param.requires_grad:\n        count=count+1\n        print(name)\nprint(count)","metadata":{"id":"a769f54e-05ad-4e3c-aae8-d00d1d9dfb2f","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T02:23:51.230365Z","iopub.execute_input":"2025-04-13T02:23:51.230673Z","iopub.status.idle":"2025-04-13T02:23:51.237031Z","shell.execute_reply.started":"2025-04-13T02:23:51.230647Z","shell.execute_reply":"2025-04-13T02:23:51.236443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print('PEFT Model')\npeft_model.print_trainable_parameters()","metadata":{"id":"da45f85c-b016-4c49-8808-6eafa7cb5d1b","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T02:23:51.237872Z","iopub.execute_input":"2025-04-13T02:23:51.238176Z","iopub.status.idle":"2025-04-13T02:23:51.251893Z","shell.execute_reply.started":"2025-04-13T02:23:51.238154Z","shell.execute_reply":"2025-04-13T02:23:51.251102Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Setup","metadata":{"id":"12284b58"}},{"cell_type":"code","source":"# To track evaluation accuracy during training\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import precision_recall_fscore_support\n\ndef compute_metrics(pred):\n    labels = pred.label_ids\n    preds = pred.predictions.argmax(-1)\n    \n    acc = accuracy_score(labels, preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\")\n\n    return {\n        \"accuracy\": acc,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n    }","metadata":{"id":"0ee64c43-fe38-479a-b3c5-7d939a3db4c1","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T03:12:10.182762Z","iopub.execute_input":"2025-04-13T03:12:10.183027Z","iopub.status.idle":"2025-04-13T03:12:10.188298Z","shell.execute_reply.started":"2025-04-13T03:12:10.183007Z","shell.execute_reply":"2025-04-13T03:12:10.187705Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import TrainingArguments, Trainer\n\ntraining_args = TrainingArguments(\n    output_dir=\"./roberta-lora-agnews\",\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    learning_rate=2e-4,\n    logging_dir=\"./logs\",\n    logging_steps=50,\n    report_to=\"none\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    label_names=[\"labels\"]\n)\n\n","metadata":{"id":"768b4917-65de-4e55-ae7f-698e287535d4","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T03:12:13.681036Z","iopub.execute_input":"2025-04-13T03:12:13.681873Z","iopub.status.idle":"2025-04-13T03:12:13.716498Z","shell.execute_reply.started":"2025-04-13T03:12:13.681849Z","shell.execute_reply":"2025-04-13T03:12:13.715797Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Start Training","metadata":{"id":"9b848278"}},{"cell_type":"code","source":"from transformers import Trainer\n\nclass CustomTrainer(Trainer):\n    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n        # Remove the unused argument before forwarding\n        if \"num_items_in_batch\" in inputs:\n            inputs.pop(\"num_items_in_batch\")\n        return super().compute_loss(model, inputs, return_outputs)\n","metadata":{"id":"98d9d57d-b57f-4acc-80fb-fc5443e75515","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T03:12:21.280774Z","iopub.execute_input":"2025-04-13T03:12:21.281045Z","iopub.status.idle":"2025-04-13T03:12:21.285644Z","shell.execute_reply.started":"2025-04-13T03:12:21.281023Z","shell.execute_reply":"2025-04-13T03:12:21.285037Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer = CustomTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=final_train_dataset,\n    eval_dataset=eval_dataset, \n    compute_metrics=compute_metrics,  \n    data_collator=data_collator\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:09:36.541900Z","iopub.execute_input":"2025-04-13T06:09:36.542734Z","iopub.status.idle":"2025-04-13T06:09:36.567921Z","shell.execute_reply.started":"2025-04-13T06:09:36.542700Z","shell.execute_reply":"2025-04-13T06:09:36.567167Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%debug\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:09:42.261304Z","iopub.execute_input":"2025-04-13T06:09:42.262004Z","iopub.status.idle":"2025-04-13T08:40:05.024903Z","shell.execute_reply.started":"2025-04-13T06:09:42.261979Z","shell.execute_reply":"2025-04-13T08:40:05.024288Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Evaluate Finetuned Model\n","metadata":{"id":"5183be7e-514f-4e64-a6f4-314a827e6be5"}},{"cell_type":"markdown","source":"### Performing Inference on Custom Input\nUncomment following functions for running inference on custom inputs","metadata":{"id":"038198cf-0953-47e7-bd47-b073d05f8378"}},{"cell_type":"code","source":"def classify(model, tokenizer, text):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n    output = model(**inputs)\n\n    prediction = output.logits.argmax(dim=-1).item()\n\n    print(f'\\n Class: {prediction}, Label: {id2label[prediction]}, Text: {text}')\n    return id2label[prediction]","metadata":{"id":"f88ad420-3f46-4eff-9d71-0ce388163062","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T08:40:36.854880Z","iopub.execute_input":"2025-04-13T08:40:36.855153Z","iopub.status.idle":"2025-04-13T08:40:36.859937Z","shell.execute_reply.started":"2025-04-13T08:40:36.855136Z","shell.execute_reply":"2025-04-13T08:40:36.859299Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"classify( peft_model, tokenizer, \"Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\")\nclassify( peft_model, tokenizer, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\")","metadata":{"id":"fc52bb94-5e13-4943-9225-a6d7fd053579","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T08:40:39.944906Z","iopub.execute_input":"2025-04-13T08:40:39.945540Z","iopub.status.idle":"2025-04-13T08:40:39.989033Z","shell.execute_reply.started":"2025-04-13T08:40:39.945516Z","shell.execute_reply":"2025-04-13T08:40:39.988466Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Run Inference on eval_dataset","metadata":{"id":"68a3e276-bf8c-4403-8a48-5ef19f2beccf"}},{"cell_type":"code","source":"!pip install evaluate\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T05:41:59.560136Z","iopub.execute_input":"2025-04-13T05:41:59.560749Z","iopub.status.idle":"2025-04-13T05:42:03.377601Z","shell.execute_reply.started":"2025-04-13T05:41:59.560726Z","shell.execute_reply":"2025-04-13T05:42:03.376505Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport evaluate\nfrom tqdm import tqdm\n\ndef evaluate_model(inference_model, dataset, labelled=True, batch_size=8, data_collator=None):\n    \"\"\"\n    Evaluate a PEFT model on a dataset.\n\n    Args:\n        inference_model: The model to evaluate.\n        dataset: The dataset (Hugging Face Dataset) to run inference on.\n        labelled (bool): If True, the dataset includes labels and metrics will be computed.\n                         If False, only predictions will be returned.\n        batch_size (int): Batch size for inference.\n        data_collator: Function to collate batches. If None, the default collate_fn is used.\n\n    Returns:\n        If labelled is True, returns a tuple (metrics, predictions)\n        If labelled is False, returns the predictions.\n    \"\"\"\n    # Create the DataLoader\n    eval_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    inference_model.to(device)\n    inference_model.eval()\n\n    all_predictions = []\n    if labelled:\n        metric = evaluate.load('accuracy')\n\n    # Loop over the DataLoader\n    for batch in tqdm(eval_dataloader):\n        # Move each tensor in the batch to the device\n        batch = {k: v.to(device) for k, v in batch.items()}\n        with torch.no_grad():\n            outputs = inference_model(**batch)\n        predictions = outputs.logits.argmax(dim=-1)\n        all_predictions.append(predictions.cpu())\n\n        if labelled:\n            # Expecting that labels are provided under the \"labels\" key.\n            references = batch[\"labels\"]\n            metric.add_batch(\n                predictions=predictions.cpu().numpy(),\n                references=references.cpu().numpy()\n            )\n\n    # Concatenate predictions from all batches\n    all_predictions = torch.cat(all_predictions, dim=0)\n\n    if labelled:\n        eval_metric = metric.compute()\n        print(\"Evaluation Metric:\", eval_metric)\n        return eval_metric, all_predictions\n    else:\n        return all_predictions","metadata":{"id":"ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T08:40:53.366316Z","iopub.execute_input":"2025-04-13T08:40:53.366919Z","iopub.status.idle":"2025-04-13T08:40:53.374149Z","shell.execute_reply.started":"2025-04-13T08:40:53.366896Z","shell.execute_reply":"2025-04-13T08:40:53.373473Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check evaluation accuracy\n_, _ = evaluate_model(peft_model, eval_dataset, True, 8, data_collator)","metadata":{"id":"809635a6-a2c7-4d09-8d60-ababd1815003","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T08:40:57.403630Z","iopub.execute_input":"2025-04-13T08:40:57.404176Z","iopub.status.idle":"2025-04-13T08:47:03.161594Z","shell.execute_reply.started":"2025-04-13T08:40:57.404155Z","shell.execute_reply":"2025-04-13T08:47:03.160862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport torch\nimport pandas as pd\nfrom torch.utils.data import DataLoader\nfrom torch.nn.functional import softmax\nfrom transformers import DataCollatorWithPadding\nfrom datasets import Dataset, concatenate_datasets\n\n# Load your unlabeled dataset (with 'text' column)\nunlabelled_dataset = pd.read_pickle(\"/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl\")\n\n# Tokenize using your existing preprocess function\ntest_dataset = unlabelled_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n\n# Set up data collator and dataloader\ndata_collator = DataCollatorWithPadding(tokenizer)\ndataloader = DataLoader(test_dataset, batch_size=32, collate_fn=data_collator)\n\n# Inference and confidence filtering\nmodel.eval()\npseudo_input_ids = []\npseudo_attention_masks = []\npseudo_labels = []\npseudo_confidences = []\n\nfor batch in dataloader:\n    batch = {k: v.to(model.device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n        probs = softmax(outputs.logits, dim=-1)\n        max_probs, preds = torch.max(probs, dim=1)\n\n        for i in range(len(preds)):\n            if max_probs[i].item() >= 0.95:  # Confidence threshold\n                pseudo_input_ids.append(batch[\"input_ids\"][i].cpu())\n                pseudo_attention_masks.append(batch[\"attention_mask\"][i].cpu())\n                pseudo_labels.append(preds[i].item())\n                pseudo_confidences.append(max_probs[i].item())\n\n# Build Hugging Face Dataset from pseudo-labeled examples\npseudo_dataset = Dataset.from_dict({\n    \"input_ids\": pseudo_input_ids,\n    \"attention_mask\": pseudo_attention_masks,\n    \"labels\": pseudo_labels\n})\n\nprint(f\"✅ Pseudo-labeled dataset size: {len(pseudo_dataset)}\")\n\n# Match label types with original training dataset\nlabel_feature = train_dataset.features[\"labels\"]\npseudo_dataset = pseudo_dataset.cast_column(\"labels\", label_feature)\n\n# Combine original and pseudo-labeled data\nfinal_train_dataset = concatenate_datasets([train_dataset, pseudo_dataset])\nprint(\"✅ Combined dataset ready for fine-tuning.\")\n\n# Save to disk for reuse\nfinal_train_dataset.save_to_disk(\"final_train_dataset\")\nprint(\"✅ Final train dataset saved to disk as 'final_train_dataset/'\")\n","metadata":{"id":"kMJgvV1ZnVhd","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T05:57:33.282874Z","iopub.execute_input":"2025-04-13T05:57:33.283213Z","iopub.status.idle":"2025-04-13T05:59:25.943704Z","shell.execute_reply.started":"2025-04-13T05:57:33.283192Z","shell.execute_reply":"2025-04-13T05:59:25.942882Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Convert to pandas and save\ndf = final_train_dataset.to_pandas()\ndf.to_pickle(\"final_train_dataset.pkl\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T06:08:18.793670Z","iopub.execute_input":"2025-04-13T06:08:18.793999Z","iopub.status.idle":"2025-04-13T06:08:21.699288Z","shell.execute_reply.started":"2025-04-13T06:08:18.793975Z","shell.execute_reply":"2025-04-13T06:08:21.698623Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Run Inference on unlabelled dataset","metadata":{"id":"75f39087-f2bb-49d3-9fe1-0d812fb30203"}},{"cell_type":"code","source":"#Load your unlabelled data\nunlabelled_dataset = pd.read_pickle(\"/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl\")\ntest_dataset = unlabelled_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\nunlabelled_dataset","metadata":{"id":"2af62541-2c33-4f16-bb1c-cc969c715cd7","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T08:48:45.774879Z","iopub.execute_input":"2025-04-13T08:48:45.775790Z","iopub.status.idle":"2025-04-13T08:48:52.242710Z","shell.execute_reply.started":"2025-04-13T08:48:45.775765Z","shell.execute_reply":"2025-04-13T08:48:52.241936Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Run inference and save predictions\npreds = evaluate_model(peft_model, test_dataset, False, 8, data_collator)\ndf_output = pd.DataFrame({\n    'ID': range(len(preds)),\n    'Label': preds.numpy()  # or preds.tolist()\n})\ndf_output.to_csv(os.path.join(\"inference_output2.csv\"), index=False)\nprint(\"Inference complete. Predictions saved to inference_output.csv\")","metadata":{"id":"e60991d3-38b1-4657-8854-408ce66f6b84","trusted":true,"execution":{"iopub.status.busy":"2025-04-13T08:51:43.651096Z","iopub.execute_input":"2025-04-13T08:51:43.651431Z","iopub.status.idle":"2025-04-13T08:53:35.082879Z","shell.execute_reply.started":"2025-04-13T08:51:43.651409Z","shell.execute_reply":"2025-04-13T08:53:35.082131Z"}},"outputs":[],"execution_count":null}]}