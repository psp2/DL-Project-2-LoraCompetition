{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e97d24ff",
    "papermill": {
     "duration": 0.007962,
     "end_time": "2025-04-16T20:37:26.681072",
     "exception": false,
     "start_time": "2025-04-16T20:37:26.67311",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Deep Learning Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e799d6c3",
    "papermill": {
     "duration": 0.006161,
     "end_time": "2025-04-16T20:37:26.693954",
     "exception": false,
     "start_time": "2025-04-16T20:37:26.687793",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Install and import required libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93.91% 84.450%\n",
    "noise and eda\n",
    "synonym replacement, word shuffle, random punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:11:34.279813Z",
     "iopub.status.busy": "2025-04-17T18:11:34.279542Z",
     "iopub.status.idle": "2025-04-17T18:11:42.574120Z",
     "shell.execute_reply": "2025-04-17T18:11:42.572763Z",
     "shell.execute_reply.started": "2025-04-17T18:11:34.279788Z"
    },
    "id": "2a53d5ba",
    "outputId": "ee8d6433-f24c-4561-c48e-05349114a0fe",
    "papermill": {
     "duration": 100.103072,
     "end_time": "2025-04-16T20:39:06.803404",
     "exception": false,
     "start_time": "2025-04-16T20:37:26.700332",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nvidia-ml-py3\n",
      "  Downloading nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: nvidia-ml-py3\n",
      "  Building wheel for nvidia-ml-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nvidia-ml-py3: filename=nvidia_ml_py3-7.352.0-py3-none-any.whl size=19173 sha256=6fabd6de6830eba7aff743667e5a4a143022717064ca6252cf65f4f7a877c896\n",
      "  Stored in directory: /root/.cache/pip/wheels/47/50/9e/29dc79037d74c3c1bb4a8661fb608e8674b7e4260d6a3f8f51\n",
      "Successfully built nvidia-ml-py3\n",
      "Installing collected packages: nvidia-ml-py3\n",
      "Successfully installed nvidia-ml-py3-7.352.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install transformers datasets evaluate accelerate peft trl bitsandbytes\n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:11:57.737445Z",
     "iopub.status.busy": "2025-04-17T18:11:57.737077Z",
     "iopub.status.idle": "2025-04-17T18:12:37.230371Z",
     "shell.execute_reply": "2025-04-17T18:12:37.228959Z",
     "shell.execute_reply.started": "2025-04-17T18:11:57.737418Z"
    },
    "id": "17a3267c",
    "outputId": "817a9637-3906-45fb-964f-25a7b4a9e6dd",
    "papermill": {
     "duration": 31.864502,
     "end_time": "2025-04-16T20:39:38.713619",
     "exception": false,
     "start_time": "2025-04-16T20:39:06.849117",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-17 18:12:17.069723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744913537.328529      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744913537.403418      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaModel, RobertaTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding, RobertaForSequenceClassification\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from datasets import load_dataset, Dataset, ClassLabel\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ff72db0",
    "papermill": {
     "duration": 0.03787,
     "end_time": "2025-04-16T20:39:38.85145",
     "exception": false,
     "start_time": "2025-04-16T20:39:38.81358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Tokenizer and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:18:14.672115Z",
     "iopub.status.busy": "2025-04-17T18:18:14.671606Z",
     "iopub.status.idle": "2025-04-17T18:18:14.681189Z",
     "shell.execute_reply": "2025-04-17T18:18:14.679980Z",
     "shell.execute_reply.started": "2025-04-17T18:18:14.672086Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Dirty augmentation utilities\n",
    "def add_random_punctuation(text, num_punct=3):\n",
    "    punctuations = list(\"\\™œ#â€“;&\")\n",
    "    words = text.split()\n",
    "    for _ in range(num_punct):\n",
    "        insert_idx = random.randint(0, len(words)-1)\n",
    "        words[insert_idx] += random.choice(punctuations)\n",
    "    return \" \".join(words)\n",
    "\n",
    "def word_shuffle(text, shuffle_ratio=0.3):\n",
    "    words = text.split()\n",
    "    n_shuffle = int(len(words) * shuffle_ratio)\n",
    "    indices = random.sample(range(len(words)), n_shuffle)\n",
    "    shuffled = words.copy()\n",
    "    for i in indices:\n",
    "        j = random.randint(0, len(words)-1)\n",
    "        shuffled[i], shuffled[j] = shuffled[j], shuffled[i]\n",
    "    return \" \".join(shuffled)\n",
    "\n",
    "def dirty_augment(text):\n",
    "    aug = add_random_punctuation(text)\n",
    "    aug = word_shuffle(aug)\n",
    "    return aug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:18:22.656135Z",
     "iopub.status.busy": "2025-04-17T18:18:22.655697Z",
     "iopub.status.idle": "2025-04-17T18:18:28.016961Z",
     "shell.execute_reply": "2025-04-17T18:18:28.015722Z",
     "shell.execute_reply.started": "2025-04-17T18:18:22.656100Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load your clean combined dataset\n",
    "raw_dataset = load_dataset(\"ag_news\", split=\"train\")\n",
    "# Get proper label info from original AG News\n",
    "original_features = load_dataset(\"ag_news\", split=\"train\").features\n",
    "\n",
    "# Convert to mutable list\n",
    "data = raw_dataset.to_list()\n",
    "\n",
    "# Choose ratio to corrupt\n",
    "dirty_ratio = 0.2\n",
    "num_dirty = int(dirty_ratio * len(data))\n",
    "\n",
    "# Shuffle and select\n",
    "indices = random.sample(range(len(data)), num_dirty)\n",
    "\n",
    "# Apply dirty augmentation in-place\n",
    "for idx in indices:\n",
    "    original_text = data[idx][\"text\"]\n",
    "    data[idx][\"text\"] = dirty_augment(original_text)\n",
    "\n",
    "# Convert back to Dataset\n",
    "dirty_injected_dataset = Dataset.from_list(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:18:34.077131Z",
     "iopub.status.busy": "2025-04-17T18:18:34.076711Z",
     "iopub.status.idle": "2025-04-17T18:18:34.150550Z",
     "shell.execute_reply": "2025-04-17T18:18:34.149378Z",
     "shell.execute_reply.started": "2025-04-17T18:18:34.077104Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"omw-1.4\")\n",
    "import random\n",
    "\n",
    "# EDA synonym replacement\n",
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wordnet.synsets(word):\n",
    "        for lemma in syn.lemmas():\n",
    "            name = lemma.name().replace(\"_\", \" \").lower()\n",
    "            if name != word:\n",
    "                synonyms.add(name)\n",
    "    return list(synonyms)\n",
    "\n",
    "def synonym_replacement(text, n=1):\n",
    "    words = text.split()\n",
    "    new_words = words.copy()\n",
    "    candidates = [w for w in words if get_synonyms(w)]\n",
    "    random.shuffle(candidates)\n",
    "\n",
    "    replaced = 0\n",
    "    for word in candidates:\n",
    "        synonyms = get_synonyms(word)\n",
    "        if synonyms:\n",
    "            synonym = random.choice(synonyms)\n",
    "            new_words = [synonym if w == word else w for w in new_words]\n",
    "            replaced += 1\n",
    "        if replaced >= n:\n",
    "            break\n",
    "    return \" \".join(new_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:18:39.164417Z",
     "iopub.status.busy": "2025-04-17T18:18:39.163979Z",
     "iopub.status.idle": "2025-04-17T18:19:12.585270Z",
     "shell.execute_reply": "2025-04-17T18:19:12.584195Z",
     "shell.execute_reply.started": "2025-04-17T18:18:39.164388Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert to list so we can work on it\n",
    "data = dirty_injected_dataset.to_list()\n",
    "\n",
    "# Get indices NOT already dirtied (you'll reuse same 20% ratio)\n",
    "eda_ratio = 0.25\n",
    "num_eda = int(eda_ratio * len(data))\n",
    "\n",
    "# Grab samples that were not dirtied (just shuffle and take a new set)\n",
    "remaining_indices = [i for i in range(len(data))]\n",
    "eda_indices = random.sample(remaining_indices, num_eda)\n",
    "\n",
    "for idx in eda_indices:\n",
    "    text = data[idx][\"text\"]\n",
    "    words = text.split()\n",
    "    n_replace = max(1, int(0.15 * len(words)))  # Replace 15% of words\n",
    "    data[idx][\"text\"] = synonym_replacement(text, n_replace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:19:22.433699Z",
     "iopub.status.busy": "2025-04-17T18:19:22.433270Z",
     "iopub.status.idle": "2025-04-17T18:19:24.760230Z",
     "shell.execute_reply": "2025-04-17T18:19:24.759127Z",
     "shell.execute_reply.started": "2025-04-17T18:19:22.433672Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358a937c2bc44f2a8b2c6d451e351459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "final_augmented_dataset = Dataset.from_list(data)\n",
    "\n",
    "# Recast label type\n",
    "original_features = load_dataset(\"ag_news\", split=\"train\").features\n",
    "final_augmented_dataset = final_augmented_dataset.cast_column(\"label\", original_features[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:19:37.310654Z",
     "iopub.status.busy": "2025-04-17T18:19:37.310311Z",
     "iopub.status.idle": "2025-04-17T18:20:57.250273Z",
     "shell.execute_reply": "2025-04-17T18:20:57.249271Z",
     "shell.execute_reply.started": "2025-04-17T18:19:37.310627Z"
    },
    "id": "cd8dd061",
    "outputId": "f8dde87b-9f39-4714-ab36-b11c5c15854a",
    "papermill": {
     "duration": 64.085076,
     "end_time": "2025-04-16T20:40:42.974326",
     "exception": false,
     "start_time": "2025-04-16T20:39:38.88925",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429a29cc0fdc437ab9e1f376d9d9dd9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/120000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = 'roberta-base'\n",
    "\n",
    "tokenizer = RobertaTokenizer.from_pretrained(base_model)\n",
    "\n",
    "def preprocess(examples):\n",
    "    tokenized = tokenizer(examples['text'], truncation=True, padding=True)\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = final_augmented_dataset.map(preprocess, batched=True,  remove_columns=[\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:21:28.069160Z",
     "iopub.status.busy": "2025-04-17T18:21:28.068702Z",
     "iopub.status.idle": "2025-04-17T18:21:28.092198Z",
     "shell.execute_reply": "2025-04-17T18:21:28.091145Z",
     "shell.execute_reply.started": "2025-04-17T18:21:28.069132Z"
    },
    "id": "b0ee9157",
    "outputId": "089163c4-4d9e-4ea1-90b9-5c80527ed959",
    "papermill": {
     "duration": 0.04463,
     "end_time": "2025-04-16T20:40:43.058985",
     "exception": false,
     "start_time": "2025-04-16T20:40:43.014355",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels: 4\n",
      "the labels: ['World', 'Sports', 'Business', 'Sci/Tech']\n"
     ]
    }
   ],
   "source": [
    "# Extract the number of classess and their names\n",
    "num_labels = final_augmented_dataset.features['label'].num_classes\n",
    "class_names = final_augmented_dataset.features[\"label\"].names\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "# Create an id2label mapping\n",
    "# We will need this for our classifier.\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:21:31.947988Z",
     "iopub.status.busy": "2025-04-17T18:21:31.947632Z",
     "iopub.status.idle": "2025-04-17T18:21:31.955406Z",
     "shell.execute_reply": "2025-04-17T18:21:31.954036Z",
     "shell.execute_reply.started": "2025-04-17T18:21:31.947956Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def show_augmented_samples(final_dataset, original_dataset, indices=None, n=5):\n",
    "    import random\n",
    "    from termcolor import colored\n",
    "\n",
    "    if indices is None:\n",
    "        indices = random.sample(range(len(final_dataset)), n)\n",
    "\n",
    "    for i in indices:\n",
    "        original = original_dataset[i][\"text\"]\n",
    "        augmented = final_dataset[i][\"text\"]\n",
    "        label = final_dataset[i][\"label\"]\n",
    "\n",
    "        print(f\"\\n🔹 Sample {i} — Label: {label}\")\n",
    "        print(colored(\"Original: \", \"cyan\"), original)\n",
    "        print(colored(\"Augmented:\", \"green\"), augmented)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T18:24:16.368032Z",
     "iopub.status.busy": "2025-04-17T18:24:16.367665Z",
     "iopub.status.idle": "2025-04-17T18:24:16.379835Z",
     "shell.execute_reply": "2025-04-17T18:24:16.378564Z",
     "shell.execute_reply.started": "2025-04-17T18:24:16.368001Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Sample 41603 — Label: 3\n",
      "Original:  Hotlines: Blue Man Group Returns in  #36;120 Mil. Centrino Campaign (AdWeek.com) AdWeek.com - NEW YORK -- Intel is reintroducing the Blue Man Group, not used since 2001, in a campaign for its Centrino mobile technology for wireless computing.\n",
      "Augmented: reintroducing its #36;120 group Returns inwards technology not (AdWeek.com) political campaign Centrino Mil. - NEW house of york blue-blooded Intel is inœ the wireless Man Group, AdWeek.com used since 2001, Hotlines: a campaign for™ -- Centrino computing. Man for blue-blooded mobile;\n",
      "\n",
      "🔹 Sample 103978 — Label: 3\n",
      "Original:  Family Tree Maker 2005 Deluxe; Law   Order: Justice Is Served; WWE Smackdown! Vs. Raw The 12th edition of this genealogy program comes in three editions -- Standard, Deluxe and Collector's -- but the core program is identical in all.\n",
      "Augmented: Family Tree Maker 2005 Deluxe; Law Order: Justice Is Served; WWE Smackdown! Vs. Raw The twelfth version of this genealogy political platform comes indiana three editions -- Standard, Deluxe and Collector's -- but the core group political platform is identical indiana all.\n",
      "\n",
      "🔹 Sample 23469 — Label: 0\n",
      "Original:  Thai killer shot Britons five times Horrific details of how two British backpackers were gunned down in cold blood near the bridge on the River Kwai were released today.\n",
      "Augmented: Thai killer shot Britons five times Horrific details of how two British backpackers were gunned down in cold blood near the bridge on the River Kwai were released today.\n",
      "\n",
      "🔹 Sample 84728 — Label: 2\n",
      "Original:  European Bank Chief Talks Up Dollar The dollar edged higher against the Swiss franc and the euro on Monday as traders took profits after the head of the European Central Bank said the euro zone unit #39;s recent \n",
      "Augmented: European“ Bank€ Chief edged Up European took the the recent against the Talks franc and higher euro on Monday as traders the profits after head the of #39;s Dollar Central Bank said Swiss euro zone unit Theâ dollar\n",
      "\n",
      "🔹 Sample 105734 — Label: 2\n",
      "Original:  SEC gives some companies a break Most US companies - although not the largest ones - were given a reprieve Tuesday from requirements imposed in the wake of the Enron and WorldCom scandals that they and their auditors certify that the companies #39; internal financial controls are adequate.\n",
      "Augmented: SEC give some company vitamin a break Most US company - although not the with child ones - constitute given vitamin a reprieve Tuesday from requirements imposed in the wake of the Enron and WorldCom scandals that they and their auditors certify that the company #39; intimate fiscal controls are adequate.\n",
      "\n",
      "🔹 Sample 23234 — Label: 3\n",
      "Original:  FCC frees up spectrum for 3G Regulators set aside additional bandwidth for third-generation cell phones and other advanced wireless services.\n",
      "Augmented: FCC frees up spectrum for 3G Regulators set aside additional bandwidth for third-generation cell phones and other advanced wireless services.\n",
      "\n",
      "🔹 Sample 104105 — Label: 3\n",
      "Original:  Toshiba wins 4 Hollywood studios #39; support for HD DVD format TOKYO, Nov 29, 2004 (Kyodo via COMTEX) -- Toshiba Corp. said Monday it has won support from four US film studios for its next-generation DVD format called HD DVD.\n",
      "Augmented: Toshiba wins 4 Hollywood studios #39; support for HD dvd format TOKYO, november 29, 2004 (Kyodo via COMTEX) -- Toshiba Corp. said Monday it give birth won support from four US picture studios for its next-generation dvd format promise HD DVD.\n",
      "\n",
      "🔹 Sample 109223 — Label: 2\n",
      "Original:  Ex-Vivendi Boss Is Fined 1 Million Euros French regulators fined Vivendi Universal (EAUG.PA: Quote, Profile, Research) and its former CEO Jean-Marie Messier one million euros each on Tuesday for \n",
      "Augmented: Ex-Vivendi Boss Is Fined 1 Million Euros French regulators fined Vivendi Universal (EAUG.PA: Quote, Profile, Research) and its former CEO Jean-Marie Messier one million euros each on Tuesday for \n",
      "\n",
      "🔹 Sample 61960 — Label: 0\n",
      "Original:  Bush Considering Tougher Syria Sanctions-Officials (Reuters) Reuters - The Bush administration is\\considering tightening U.S. economic sanctions on Syria to put\\pressure on Damascus to pull its troops out of Lebanon and\\crack down on terrorism, administration officials said on\\Friday.\n",
      "Augmented: Bush moot baffling Syria Sanctions-Officials (Reuters) Reuters - The Bush administration is\\considering reduce U.S. economic authorisation on Syria to put\\pressure on Damascus to pull its troops out of Lebanon and\\crack push down on terrorism, administration officials said on\\Friday.\n",
      "\n",
      "🔹 Sample 92034 — Label: 3\n",
      "Original:  Dell announces new enterprise-class blade servers Dell has introduced its new PowerEdge 1855 blade servers, which it says combine enterprise-class features with increased density and lower cost than traditional Dell 1U rack servers to deliver an advantaged platform for data center computing.\n",
      "Augmented: Dell announces new enterprise-class blade servers Dell has introduced its new PowerEdge 1855 blade servers, which it says combine enterprise-class features with increased density and lower cost than traditional Dell 1U rack servers to deliver an advantaged platform for data center computing.\n"
     ]
    }
   ],
   "source": [
    "show_augmented_samples(final_augmented_dataset, raw_dataset, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b99b93e8",
    "papermill": {
     "duration": 0.037689,
     "end_time": "2025-04-16T20:40:43.136407",
     "exception": false,
     "start_time": "2025-04-16T20:40:43.098718",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load Pre-trained Model\n",
    "Set up config for pretrained model and download it from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T16:59:58.869144Z",
     "iopub.status.busy": "2025-04-17T16:59:58.868849Z",
     "iopub.status.idle": "2025-04-17T17:00:01.352429Z",
     "shell.execute_reply": "2025-04-17T17:00:01.351608Z",
     "shell.execute_reply.started": "2025-04-17T16:59:58.869126Z"
    },
    "id": "cf638294",
    "outputId": "244cfd2b-9903-452e-9d10-0abeff0502f7",
    "papermill": {
     "duration": 2.673971,
     "end_time": "2025-04-16T20:40:45.847993",
     "exception": false,
     "start_time": "2025-04-16T20:40:43.174022",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    base_model,\n",
    "    id2label=id2label)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69df03a9",
    "papermill": {
     "duration": 0.038029,
     "end_time": "2025-04-16T20:40:45.925222",
     "exception": false,
     "start_time": "2025-04-16T20:40:45.887193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Anything from here on can be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T17:00:07.912957Z",
     "iopub.status.busy": "2025-04-17T17:00:07.912577Z",
     "iopub.status.idle": "2025-04-17T17:00:07.978815Z",
     "shell.execute_reply": "2025-04-17T17:00:07.977511Z",
     "shell.execute_reply.started": "2025-04-17T17:00:07.912936Z"
    },
    "id": "56a3cad3",
    "papermill": {
     "duration": 0.077776,
     "end_time": "2025-04-16T20:40:46.041095",
     "exception": false,
     "start_time": "2025-04-16T20:40:45.963319",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Split the original training set\n",
    "split_datasets = tokenized_dataset.train_test_split(test_size=640, seed=42)\n",
    "train_dataset = split_datasets['train']\n",
    "eval_dataset = split_datasets['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0b72b245",
    "papermill": {
     "duration": 0.039698,
     "end_time": "2025-04-16T20:40:46.119833",
     "exception": false,
     "start_time": "2025-04-16T20:40:46.080135",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Setup LoRA Config\n",
    "Setup PEFT config and get peft model for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:53.113347Z",
     "iopub.status.busy": "2025-04-17T02:44:53.113104Z",
     "iopub.status.idle": "2025-04-17T02:44:56.412642Z",
     "shell.execute_reply": "2025-04-17T02:44:56.411535Z",
     "shell.execute_reply.started": "2025-04-17T02:44:53.113326Z"
    },
    "id": "ff28f783",
    "outputId": "5e76af90-486f-4049-845a-96295a5a11fc",
    "papermill": {
     "duration": 3.362029,
     "end_time": "2025-04-16T20:40:49.520343",
     "exception": false,
     "start_time": "2025-04-16T20:40:46.158314",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install peft accelerate transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:56.41415Z",
     "iopub.status.busy": "2025-04-17T02:44:56.413908Z",
     "iopub.status.idle": "2025-04-17T02:44:56.520836Z",
     "shell.execute_reply": "2025-04-17T02:44:56.520175Z",
     "shell.execute_reply.started": "2025-04-17T02:44:56.414127Z"
    },
    "id": "73f93c45",
    "outputId": "e7a3296b-4627-40a2-85b8-5b036c21def9",
    "papermill": {
     "duration": 0.138791,
     "end_time": "2025-04-16T20:40:49.698491",
     "exception": false,
     "start_time": "2025-04-16T20:40:49.5597",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "# Configure LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=8,  #back to 8\n",
    "    lora_alpha=8, # back to 8\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.1, # bumping up dropout\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_CLS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:56.521697Z",
     "iopub.status.busy": "2025-04-17T02:44:56.521502Z",
     "iopub.status.idle": "2025-04-17T02:44:56.56204Z",
     "shell.execute_reply": "2025-04-17T02:44:56.561342Z",
     "shell.execute_reply.started": "2025-04-17T02:44:56.521683Z"
    },
    "id": "ba47ff9e",
    "outputId": "9639905e-0865-41f6-d0d9-745945217fc1",
    "papermill": {
     "duration": 0.075477,
     "end_time": "2025-04-16T20:40:49.813831",
     "exception": false,
     "start_time": "2025-04-16T20:40:49.738354",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(model, lora_config)\n",
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:56.563562Z",
     "iopub.status.busy": "2025-04-17T02:44:56.563364Z",
     "iopub.status.idle": "2025-04-17T02:44:56.569558Z",
     "shell.execute_reply": "2025-04-17T02:44:56.568756Z",
     "shell.execute_reply.started": "2025-04-17T02:44:56.563548Z"
    },
    "id": "6b4b60c5",
    "outputId": "98719af2-5d37-4069-d3a8-f85e8bd0500f",
    "papermill": {
     "duration": 0.04686,
     "end_time": "2025-04-16T20:40:49.901515",
     "exception": false,
     "start_time": "2025-04-16T20:40:49.854655",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"Trainable parameters:\")\n",
    "count = 0\n",
    "for name, param in peft_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        count=count+1\n",
    "        print(name)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:56.570533Z",
     "iopub.status.busy": "2025-04-17T02:44:56.570288Z",
     "iopub.status.idle": "2025-04-17T02:44:56.584814Z",
     "shell.execute_reply": "2025-04-17T02:44:56.584232Z",
     "shell.execute_reply.started": "2025-04-17T02:44:56.570512Z"
    },
    "id": "06c282a9",
    "outputId": "1f2ca54c-f78e-4615-a561-d559396576d0",
    "papermill": {
     "duration": 0.046025,
     "end_time": "2025-04-16T20:40:49.98709",
     "exception": false,
     "start_time": "2025-04-16T20:40:49.941065",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('PEFT Model')\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a2d5f09b",
    "papermill": {
     "duration": 0.039625,
     "end_time": "2025-04-16T20:40:50.067733",
     "exception": false,
     "start_time": "2025-04-16T20:40:50.028108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:56.585794Z",
     "iopub.status.busy": "2025-04-17T02:44:56.585548Z",
     "iopub.status.idle": "2025-04-17T02:44:56.598145Z",
     "shell.execute_reply": "2025-04-17T02:44:56.597358Z",
     "shell.execute_reply.started": "2025-04-17T02:44:56.585779Z"
    },
    "id": "a71054cc",
    "papermill": {
     "duration": 0.046269,
     "end_time": "2025-04-16T20:40:50.155173",
     "exception": false,
     "start_time": "2025-04-16T20:40:50.108904",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# To track evaluation accuracy during training\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"macro\")\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:56.599265Z",
     "iopub.status.busy": "2025-04-17T02:44:56.599006Z",
     "iopub.status.idle": "2025-04-17T02:44:56.643131Z",
     "shell.execute_reply": "2025-04-17T02:44:56.642384Z",
     "shell.execute_reply.started": "2025-04-17T02:44:56.599249Z"
    },
    "id": "b98decaf",
    "papermill": {
     "duration": 0.075995,
     "end_time": "2025-04-16T20:40:50.271479",
     "exception": false,
     "start_time": "2025-04-16T20:40:50.195484",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./roberta-lora-agnews-v2\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16, # reducing to 16 to improve generalization\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=2e-4, # significant increase, but slightly lower than common lora LR of 2e-2\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"steps\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "23c4afee",
    "papermill": {
     "duration": 0.039304,
     "end_time": "2025-04-16T20:40:50.351114",
     "exception": false,
     "start_time": "2025-04-16T20:40:50.31181",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7bd710a2",
    "papermill": {
     "duration": 0.039744,
     "end_time": "2025-04-16T20:40:50.430141",
     "exception": false,
     "start_time": "2025-04-16T20:40:50.390397",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Introducing weighted crossentropy loss\n",
    "\n",
    "Rationale behind adding Weighted Loss Trainer is that we were having uneven performance for different classes (see our metrics per business, science / tech, etc. in plots below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:56.646541Z",
     "iopub.status.busy": "2025-04-17T02:44:56.646028Z",
     "iopub.status.idle": "2025-04-17T02:44:56.65026Z",
     "shell.execute_reply": "2025-04-17T02:44:56.64963Z",
     "shell.execute_reply.started": "2025-04-17T02:44:56.646525Z"
    },
    "id": "5c3a3a27",
    "papermill": {
     "duration": 0.046205,
     "end_time": "2025-04-16T20:40:50.515997",
     "exception": false,
     "start_time": "2025-04-16T20:40:50.469792",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "def get_class_weights(labels, num_classes):\n",
    "    counts = Counter(labels)\n",
    "    total = sum(counts.values())\n",
    "\n",
    "    # Inverse frequency: total / (count * num_classes)\n",
    "    weights = [total / (counts[i] * num_classes) for i in range(num_classes)]\n",
    "    return torch.tensor(weights, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:56.651046Z",
     "iopub.status.busy": "2025-04-17T02:44:56.650863Z",
     "iopub.status.idle": "2025-04-17T02:44:56.665827Z",
     "shell.execute_reply": "2025-04-17T02:44:56.66512Z",
     "shell.execute_reply.started": "2025-04-17T02:44:56.651033Z"
    },
    "id": "060b4ff6",
    "papermill": {
     "duration": 0.047217,
     "end_time": "2025-04-16T20:40:50.602404",
     "exception": false,
     "start_time": "2025-04-16T20:40:50.555187",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "# Adding WeightedLossTrainer after observing uneven performance for different classes\n",
    "class WeightedLossTrainer(Trainer):\n",
    "    def __init__(self, *args, class_weights=None, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss_fn = torch.nn.CrossEntropyLoss(weight=self.class_weights.to(logits.device))\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:56.66684Z",
     "iopub.status.busy": "2025-04-17T02:44:56.666657Z",
     "iopub.status.idle": "2025-04-17T02:44:57.612858Z",
     "shell.execute_reply": "2025-04-17T02:44:57.611927Z",
     "shell.execute_reply.started": "2025-04-17T02:44:56.666826Z"
    },
    "id": "f532dafb",
    "papermill": {
     "duration": 0.993816,
     "end_time": "2025-04-16T20:40:51.636325",
     "exception": false,
     "start_time": "2025-04-16T20:40:50.642509",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_labels = train_dataset[\"labels\"]\n",
    "class_weights = get_class_weights(train_labels, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:57.613945Z",
     "iopub.status.busy": "2025-04-17T02:44:57.613752Z",
     "iopub.status.idle": "2025-04-17T02:44:57.967716Z",
     "shell.execute_reply": "2025-04-17T02:44:57.96697Z",
     "shell.execute_reply.started": "2025-04-17T02:44:57.613931Z"
    },
    "id": "69ad6bdf",
    "outputId": "8d37e01e-d0ce-4256-d747-de929b6ec8b7",
    "papermill": {
     "duration": 0.402542,
     "end_time": "2025-04-16T20:40:52.079838",
     "exception": false,
     "start_time": "2025-04-16T20:40:51.677296",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer = WeightedLossTrainer(\n",
    "    model=peft_model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    class_weights=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-17T02:44:57.968641Z",
     "iopub.status.busy": "2025-04-17T02:44:57.968438Z"
    },
    "id": "c563bdfe",
    "outputId": "30830892-f07c-43a5-e8ac-85167aba60df",
    "papermill": {
     "duration": 10879.520845,
     "end_time": "2025-04-16T23:42:11.642204",
     "exception": false,
     "start_time": "2025-04-16T20:40:52.121359",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f73994e",
    "papermill": {
     "duration": 0.043743,
     "end_time": "2025-04-16T23:42:11.730679",
     "exception": false,
     "start_time": "2025-04-16T23:42:11.686936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Training Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5c31bfaa",
    "papermill": {
     "duration": 0.047931,
     "end_time": "2025-04-16T23:42:11.819851",
     "exception": false,
     "start_time": "2025-04-16T23:42:11.77192",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "logs = trainer.state.log_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "629fd62d",
    "outputId": "54a95f51-7209-4ed6-b59f-e5b2e292bd81",
    "papermill": {
     "duration": 0.10843,
     "end_time": "2025-04-16T23:42:11.976994",
     "exception": false,
     "start_time": "2025-04-16T23:42:11.868564",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "log_df = pd.DataFrame(logs)\n",
    "log_df = log_df[log_df[\"step\"].notnull()]  # keep rows that are tied to steps\n",
    "log_df.reset_index(drop=True, inplace=True)\n",
    "log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "43a99c44",
    "outputId": "b64619db-3480-4238-bb68-4c8f9c87dc96",
    "papermill": {
     "duration": 0.628356,
     "end_time": "2025-04-16T23:45:19.238284",
     "exception": false,
     "start_time": "2025-04-16T23:45:18.609928",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Clean the DataFrame: remove rows without step\n",
    "log_df = log_df[log_df[\"step\"].notnull()]\n",
    "log_df = log_df.reset_index(drop=True)\n",
    "\n",
    "# Fill train loss forward (every other row has it missing)\n",
    "log_df[\"train_loss\"] = log_df[\"loss\"].fillna(method=\"ffill\")\n",
    "\n",
    "# Filter to rows with evaluation metrics\n",
    "eval_df = log_df[log_df[\"eval_accuracy\"].notnull()]\n",
    "\n",
    "# Plotting\n",
    "def plot_metrics_from_csv(log_df, eval_df):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Evaluation Metrics\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(eval_df[\"step\"], eval_df[\"eval_accuracy\"], label=\"Accuracy\")\n",
    "    plt.plot(eval_df[\"step\"], eval_df[\"eval_precision\"], label=\"Precision\")\n",
    "    plt.plot(eval_df[\"step\"], eval_df[\"eval_recall\"], label=\"Recall\")\n",
    "    plt.plot(eval_df[\"step\"], eval_df[\"eval_f1\"], label=\"F1 Score\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Evaluation Metrics Over Steps\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Training vs Evaluation Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(log_df[\"step\"], log_df[\"train_loss\"], label=\"Train Loss\", linestyle=\"--\")\n",
    "    plt.plot(eval_df[\"step\"], eval_df[\"eval_loss\"], label=\"Eval Loss\")\n",
    "    plt.xlabel(\"Step\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Train vs Eval Loss Over Steps\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_metrics_from_csv(log_df, eval_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2a9fc79f",
    "outputId": "1a5822bb-d552-4df7-c1d2-e33b70fc5834",
    "papermill": {
     "duration": 0.069193,
     "end_time": "2025-04-16T23:45:19.36399",
     "exception": false,
     "start_time": "2025-04-16T23:45:19.294797",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# log_df.to_csv(\"training_metrics V5.1.csv\", index=False)\n",
    "# print(\"Training metrics saved to training_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "46e215cc",
    "papermill": {
     "duration": 0.065251,
     "end_time": "2025-04-16T23:45:19.483877",
     "exception": false,
     "start_time": "2025-04-16T23:45:19.418626",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "## Plan to later compare models\n",
    "\n",
    "# log_df = pd.read_csv(\"training_metrics V5.1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2f2c71bd",
    "papermill": {
     "duration": 0.053409,
     "end_time": "2025-04-16T23:45:19.59167",
     "exception": false,
     "start_time": "2025-04-16T23:45:19.538261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Evaluate Finetuned Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7bedf5c",
    "papermill": {
     "duration": 0.052235,
     "end_time": "2025-04-16T23:45:19.695987",
     "exception": false,
     "start_time": "2025-04-16T23:45:19.643752",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Performing Inference on Custom Input\n",
    "Uncomment following functions for running inference on custom inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ca7d1a2",
    "papermill": {
     "duration": 0.059022,
     "end_time": "2025-04-16T23:45:19.80724",
     "exception": false,
     "start_time": "2025-04-16T23:45:19.748218",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def classify(model, tokenizer, text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "    output = model(**inputs)\n",
    "\n",
    "    prediction = output.logits.argmax(dim=-1).item()\n",
    "\n",
    "    print(f'\\n Class: {prediction}, Label: {id2label[prediction]}, Text: {text}')\n",
    "    return id2label[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b8863a69",
    "outputId": "b906ea9f-1eb2-4a4a-82eb-cbd94d49c72b",
    "papermill": {
     "duration": 0.124548,
     "end_time": "2025-04-16T23:45:19.985015",
     "exception": false,
     "start_time": "2025-04-16T23:45:19.860467",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "classify( peft_model, tokenizer, \"Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\")\n",
    "classify( peft_model, tokenizer, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce1a1d30",
    "papermill": {
     "duration": 0.053144,
     "end_time": "2025-04-16T23:45:20.092465",
     "exception": false,
     "start_time": "2025-04-16T23:45:20.039321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Run Inference on eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3e6417b",
    "outputId": "58ecaf76-bbfa-469a-fd67-3e6b9452e63b",
    "papermill": {
     "duration": 3.470826,
     "end_time": "2025-04-16T23:45:23.616425",
     "exception": false,
     "start_time": "2025-04-16T23:45:20.145599",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "320d2c0a",
    "papermill": {
     "duration": 0.361294,
     "end_time": "2025-04-16T23:45:24.033146",
     "exception": false,
     "start_time": "2025-04-16T23:45:23.671852",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "def evaluate_model(inference_model, dataset, labelled=True, batch_size=8, data_collator=None):\n",
    "    \"\"\"\n",
    "    Evaluate a PEFT model on a dataset.\n",
    "\n",
    "    Returns:\n",
    "        If labelled is True:\n",
    "            - metrics (dict)\n",
    "            - predictions (tensor)\n",
    "            - true labels (tensor)\n",
    "        Else:\n",
    "            - predictions only\n",
    "    \"\"\"\n",
    "    eval_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    inference_model.to(device)\n",
    "    inference_model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    if labelled:\n",
    "        accuracy_metric = evaluate.load(\"accuracy\")\n",
    "        precision_metric = evaluate.load(\"precision\")\n",
    "        recall_metric = evaluate.load(\"recall\")\n",
    "        f1_metric = evaluate.load(\"f1\")\n",
    "\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = inference_model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "        all_predictions.append(predictions.cpu())\n",
    "\n",
    "        if labelled:\n",
    "            labels = batch[\"labels\"].cpu()\n",
    "            all_labels.append(labels)\n",
    "\n",
    "            accuracy_metric.add_batch(predictions=predictions.cpu().numpy(), references=labels.numpy())\n",
    "            precision_metric.add_batch(predictions=predictions.cpu().numpy(), references=labels.numpy())\n",
    "            recall_metric.add_batch(predictions=predictions.cpu().numpy(), references=labels.numpy())\n",
    "            f1_metric.add_batch(predictions=predictions.cpu().numpy(), references=labels.numpy())\n",
    "\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "\n",
    "    if labelled:\n",
    "        all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "        # Introducing other metrics for better assessment and improvmeent of model\n",
    "        eval_metric = {\n",
    "            \"accuracy\": accuracy_metric.compute(),\n",
    "            \"precision\": precision_metric.compute(average=\"macro\"),\n",
    "            \"recall\": recall_metric.compute(average=\"macro\"),\n",
    "            \"f1\": f1_metric.compute(average=\"macro\"),\n",
    "        }\n",
    "\n",
    "        print(\"Evaluation Metrics:\", eval_metric)\n",
    "        return eval_metric, all_predictions, all_labels\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd79a016",
    "outputId": "4ead7fa3-33d5-495d-8321-6d19670b43e8",
    "papermill": {
     "duration": 14.524905,
     "end_time": "2025-04-16T23:45:38.613954",
     "exception": false,
     "start_time": "2025-04-16T23:45:24.089049",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "metrics, predictions, labels = evaluate_model(\n",
    "    peft_model,\n",
    "    eval_dataset,\n",
    "    labelled=True,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8df5d1f1",
    "outputId": "aa92efb7-ea2d-49ff-b55a-92028d27986d",
    "papermill": {
     "duration": 0.084919,
     "end_time": "2025-04-16T23:45:38.770915",
     "exception": false,
     "start_time": "2025-04-16T23:45:38.685996",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class_names = dataset.features[\"label\"].names\n",
    "\n",
    "print(\"\\nPer-Class Metrics:\\n\")\n",
    "print(classification_report(labels.numpy(), predictions.numpy(), target_names=class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "561c5c50",
    "papermill": {
     "duration": 0.077072,
     "end_time": "2025-04-16T23:45:38.917009",
     "exception": false,
     "start_time": "2025-04-16T23:45:38.839937",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_per_class_f1(preds, labels, class_names):\n",
    "#     report = classification_report(\n",
    "#         labels.numpy(),\n",
    "#         preds.numpy(),\n",
    "#         target_names=class_names,\n",
    "#         output_dict=True\n",
    "#     )\n",
    "#     f1_scores = {cls: report[cls][\"f1-score\"] for cls in class_names}\n",
    "\n",
    "#     plt.figure(figsize=(10, 5))\n",
    "#     plt.bar(f1_scores.keys(), f1_scores.values())\n",
    "#     plt.ylim(0, 1)\n",
    "#     plt.ylabel(\"F1 Score\")\n",
    "#     plt.title(\"Per-Class F1 Scores\")\n",
    "#     plt.xticks(rotation=45)\n",
    "#     plt.grid(axis='y')\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "266d5a67",
    "outputId": "bca328a7-f149-486d-d705-49208e1b8031",
    "papermill": {
     "duration": 0.239331,
     "end_time": "2025-04-16T23:45:39.220391",
     "exception": false,
     "start_time": "2025-04-16T23:45:38.98106",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# plot_per_class_f1(predictions, labels, class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dd160bd0",
    "outputId": "2454df1e-3c27-4126-fe0f-058f7c72d4a3",
    "papermill": {
     "duration": 3.277853,
     "end_time": "2025-04-16T23:45:42.571083",
     "exception": false,
     "start_time": "2025-04-16T23:45:39.29323",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "332ce7d9",
    "papermill": {
     "duration": 0.436488,
     "end_time": "2025-04-16T23:45:43.067243",
     "exception": false,
     "start_time": "2025-04-16T23:45:42.630755",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(predictions, labels, class_names):\n",
    "    cm = confusion_matrix(labels, predictions)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    ax = sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "\n",
    "    ax.set_xticks(range(len(class_names)))\n",
    "    ax.set_xticklabels(class_names, rotation=45)\n",
    "\n",
    "    ax.set_yticks(range(len(class_names)))\n",
    "    ax.set_yticklabels(class_names, rotation=0)\n",
    "\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b6ef956f",
    "outputId": "4af8e534-5b17-4684-8d79-4591a2ec5c29",
    "papermill": {
     "duration": 0.316566,
     "end_time": "2025-04-16T23:45:43.444365",
     "exception": false,
     "start_time": "2025-04-16T23:45:43.127799",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(predictions.numpy(), labels.numpy(), class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2cff648e",
    "papermill": {
     "duration": 0.069115,
     "end_time": "2025-04-16T23:45:43.577981",
     "exception": false,
     "start_time": "2025-04-16T23:45:43.508866",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# df = pd.DataFrame({\"predictions\": predictions, \"labels\": labels})\n",
    "# df.to_csv(\"confusion_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ea01e59",
    "papermill": {
     "duration": 0.057595,
     "end_time": "2025-04-16T23:45:43.694696",
     "exception": false,
     "start_time": "2025-04-16T23:45:43.637101",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Run Inference on unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "be8840a8",
    "outputId": "217bfc9a-d476-4ee9-d0df-a37cd1caa4b4",
    "papermill": {
     "duration": 6.374959,
     "end_time": "2025-04-16T23:45:50.131442",
     "exception": false,
     "start_time": "2025-04-16T23:45:43.756483",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Load your unlabelled data\n",
    "unlabelled_dataset = pd.read_pickle(\"/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl\")\n",
    "test_dataset = unlabelled_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "unlabelled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cd2acce7",
    "outputId": "a411fbff-95a9-4626-ff3d-31219a902e7e",
    "papermill": {
     "duration": 115.47246,
     "end_time": "2025-04-16T23:47:45.670341",
     "exception": false,
     "start_time": "2025-04-16T23:45:50.197881",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Run inference and save predictions\n",
    "preds = evaluate_model(peft_model, test_dataset, False, 8, data_collator)\n",
    "df_output = pd.DataFrame({\n",
    "    'ID': range(len(preds)),\n",
    "    'Label': preds.numpy()  # or preds.tolist()\n",
    "})\n",
    "\n",
    "df_output.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "print(\"Inference complete. Predictions saved to submission.csv\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11711500,
     "sourceId": 98084,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 11427.014944,
   "end_time": "2025-04-16T23:47:49.333931",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-16T20:37:22.318987",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
